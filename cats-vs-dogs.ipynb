{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "\n",
    "original_dataset_dir = \"./train\"\n",
    "train_cats_dir = \"./train/cats\"\n",
    "train_dogs_dir = \"./train/dogs\"\n",
    "\n",
    "fnames = [\"dog.{}.jpg\".format(i) for i in range(1000)]\n",
    "\n",
    "for fname in fnames:\n",
    "    from_data = original_dataset_dir + \"/\" + fname\n",
    "    to_data = train_dogs_dir + \"/\" + fname\n",
    "    shutil.copyfile(from_data, to_data)\n",
    "\n",
    "fnames = [\"cat.{}.jpg\".format(i) for i in range(1000)]\n",
    " \n",
    "for fname in fnames:\n",
    "    from_data = original_dataset_dir + \"/\" + fname\n",
    "    to_data = train_cats_dir + \"/\" + fname\n",
    "    shutil.copyfile(from_data, to_data)\n",
    "    \n",
    "fnames = [\"dog.{}.jpg\".format(i) for i in range(1000)]\n",
    " \n",
    "for fname in fnames:\n",
    "    from_data = original_dataset_dir + \"/\" + fname\n",
    "    to_data = train_dogs_dir + \"/\" + fname\n",
    "    shutil.copyfile(from_data, to_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_cats_dir = \"validation/cats\"\n",
    "validation_dogs_dir = \"validation/dogs\"\n",
    "\n",
    "\n",
    "fnames = [\"cat.{}.jpg\".format(i) for i in range(1000,1500)]\n",
    " \n",
    "for fname in fnames:\n",
    "    from_data = original_dataset_dir + \"/\" + fname\n",
    "    to_data = validation_cats_dir + \"/\" + fname\n",
    "    shutil.copyfile(from_data, to_data)\n",
    " \n",
    "fnames = [\"dog.{}.jpg\".format(i) for i in range(1000,1500)]\n",
    " \n",
    "for fname in fnames:\n",
    "    from_data = original_dataset_dir + \"/\" + fname\n",
    "    to_data = validation_dogs_dir + \"/\" + fname\n",
    "    shutil.copyfile(from_data, to_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cats_dir = \"test/cats\"\n",
    "test_dogs_dir = \"test/dogs\"\n",
    "\n",
    "fnames = [\"cat.{}.jpg\".format(i) for i in range(1500,2000)]\n",
    " \n",
    "for fname in fnames:\n",
    "    from_data = original_dataset_dir + \"/\" + fname\n",
    "    to_data = test_cats_dir + \"/\" + fname\n",
    "    shutil.copyfile(from_data, to_data)\n",
    " \n",
    "fnames = [\"dog.{}.jpg\".format(i) for i in range(1500,2000)]\n",
    " \n",
    "for fname in fnames:\n",
    "    from_data = original_dataset_dir + \"/\" + fname\n",
    "    to_data = test_dogs_dir + \"/\" + fname\n",
    "    shutil.copyfile(from_data, to_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"train cat:{}\".format(len(os.listdir(train_cats_dir))))\n",
    "print(\"train dog:{}\".format(len(os.listdir(train_dogs_dir))))\n",
    " \n",
    "print(\"validation cat:{}\".format(len(os.listdir(validation_cats_dir))))\n",
    "print(\"validation dog:{}\".format(len(os.listdir(validation_dogs_dir))))\n",
    " \n",
    "print(\"test cat:{}\".format(len(os.listdir(test_cats_dir))))\n",
    "print(\"test dog:{}\".format(len(os.listdir(test_dogs_dir))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ネットワークの作成\n",
    "from keras import layers\n",
    "from keras import models\n",
    " \n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32,(3,3),activation=\"relu\",input_shape=(150,150,3)))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    " \n",
    "model.add(layers.Conv2D(64,(3,3),activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    " \n",
    "model.add(layers.Conv2D(128,(3,3),activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    " \n",
    "model.add(layers.Conv2D(128,(3,3),activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    " \n",
    "model.add(layers.Flatten())\n",
    " \n",
    "model.add(layers.Dense(512,activation=\"relu\"))\n",
    "model.add(layers.Dense(1,activation=\"sigmoid\"))\n",
    " \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "# 2値分類では、活性化関数は「sigmoid」、損失関数は「binary_crossentropy」を使うのが一般的\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "             optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "             metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習にかけるためには、画像ファイルに以下の前処理を行う\n",
    "\n",
    "1. 画像ファイルを読み込む\n",
    "1. 浮動小数点数型(float型)にする\n",
    "1. ピクセル値(0-255)を、[0,1]の範囲の値にする\n",
    "\n",
    "* target_sizeは、画像のサイズです。上では150,150のサイズにリサイズします。\n",
    "* batch_sizeは、一度に処理する画像の枚数です。20枚を1バッチとします。\n",
    "* class_modeは、”binary”として二値のラベルを作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import scipy\n",
    "\n",
    "train_dir = \"train\"\n",
    "validation_dir = \"validation\"\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    " \n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150,150),\n",
    "    batch_size=20,\n",
    "    class_mode=\"binary\"\n",
    ")\n",
    " \n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(150,150),\n",
    "    batch_size=20,\n",
    "    class_mode=\"binary\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data,label in train_generator:\n",
    "    print(data.shape)\n",
    "    print(label.shape)\n",
    "    break\n",
    "\n",
    "\n",
    "(20, 150, 150, 3)\n",
    "(20,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(train_generator,\n",
    "                             steps_per_epoch=100,\n",
    "                             epochs=30,\n",
    "                             validation_data=validation_generator,\n",
    "                             validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    " \n",
    "\n",
    "acc = history.history[\"acc\"]\n",
    "val_acc = history.history[\"val_acc\"]\n",
    "loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    " \n",
    "epochs = range(1,len(acc) + 1)\n",
    " \n",
    "plt.plot(epochs, acc,\"bo\",label=\"Training Acc\")\n",
    "plt.plot(epochs, val_acc,\"b\",label=\"Validation Acc\")\n",
    "plt.legend()\n",
    " \n",
    "plt.figure()\n",
    " \n",
    "plt.plot(epochs,loss,\"bo\",label=\"Training Loss\")\n",
    "plt.plot(epochs,val_loss,\"b\",label=\"Validation Loss\")\n",
    "plt.legend()\n",
    " \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
